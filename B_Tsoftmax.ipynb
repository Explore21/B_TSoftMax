{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    " #from keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Lambda, Multiply\n",
    "from tensorflow.keras import backend as K\n",
    "import cv2, numpy as np\n",
    "import glob\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.activations import relu \n",
    "import keras as keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import  Input,Conv2D,BatchNormalization,Activation,Lambda,Subtract,concatenate,Add,add\n",
    "\n",
    "from tensorflow.keras.layers import Input, concatenate, Conv2D, MaxPooling2D, Conv2DTranspose,DepthwiseConv2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import backend as K\n",
    " \n",
    "import os\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.callbacks import EarlyStopping \n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from  sklearn.model_selection import train_test_split\n",
    "\n",
    "#from tensorflow.python import debug as tf_debug\n",
    "import imageio\n",
    "import glob\n",
    "from skimage import transform as tf\n",
    "\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as plt_img\n",
    "import scipy\n",
    "import scipy\n",
    "import skimage\n",
    "import re\n",
    "#import LRFinder\n",
    "import math as m\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, LearningRateScheduler \n",
    "from tensorflow.keras import backend as K\n",
    "from pathlib import Path\n",
    " \n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "import numpy as np\n",
    " \n",
    "from keras import backend as K\n",
    "from skimage.measure import compare_ssim, compare_psnr\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "tf.random.Generator = None \n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "from scipy.fftpack import dct, idct\n",
    "import copy\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (X_test, Y_test) = tf.keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 50000 10000 10000\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train), len(y_train),  len(X_test), len(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 10) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "num_labels = len(np.unique(y_train))\n",
    "y_train = to_categorical(y_train)\n",
    "Y_test = to_categorical(Y_test)\n",
    "\n",
    "print(y_train.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.keras.utils.normalize(x_train, axis=-1, order=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "image_size = x_train.shape[1]\n",
    "\n",
    "x_train = np.reshape(x_train,[-1, image_size, image_size, 3])\n",
    "X_test = np.reshape(X_test,[-1, image_size, image_size, 3])\n",
    "\n",
    "x_train = x_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255\n",
    "\n",
    "print(x_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "\n",
    "# from sparse label to categorical\n",
    " \n",
    "\n",
    "# reshape and normalize input images\n",
    " \n",
    "x_val=X_test[:8000]\n",
    "y_val=Y_test[:8000]\n",
    "x_test=X_test[8001:]\n",
    "y_test=Y_test[8001:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 50000 8000 8000 1999 1999\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train), len(y_train), len(x_val), len(y_val), len(x_test), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# network parameters\n",
    "input_shape = (image_size, image_size, 3)\n",
    "batch_size = 128\n",
    "kernel_size = 3\n",
    "filters = 64\n",
    "dropout = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 32)        18464     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 16)          4624      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 35,130\n",
      "Trainable params: 35,130\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=input_shape)\n",
    "y = Conv2D(filters=filters,kernel_size=kernel_size,activation='relu',padding='same')(inputs)\n",
    "y = MaxPooling2D()(y)\n",
    "y = Conv2D(filters=filters//2,kernel_size=kernel_size,activation='relu',padding='same')(y)\n",
    "y = MaxPooling2D()(y)\n",
    "y = Conv2D(filters=filters//4,kernel_size=kernel_size,activation='relu',padding='same')(y)\n",
    " \n",
    "y = Flatten()(y)\n",
    " \n",
    "y = Dropout(dropout)(y)\n",
    "outputs = Dense(num_labels, activation='softmax')(y)\n",
    "\n",
    " \n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    " \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 1999 samples\n",
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 7s 145us/sample - loss: 1.9068 - accuracy: 0.3063 - val_loss: 1.6320 - val_accuracy: 0.4237\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 6s 115us/sample - loss: 1.5870 - accuracy: 0.4225 - val_loss: 1.4990 - val_accuracy: 0.4617\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 6s 113us/sample - loss: 1.4690 - accuracy: 0.4670 - val_loss: 1.3980 - val_accuracy: 0.4907\n",
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 6s 113us/sample - loss: 1.3995 - accuracy: 0.4981 - val_loss: 1.3324 - val_accuracy: 0.5103\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 6s 113us/sample - loss: 1.3503 - accuracy: 0.5168 - val_loss: 1.3049 - val_accuracy: 0.5268\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 6s 114us/sample - loss: 1.3110 - accuracy: 0.5344 - val_loss: 1.2938 - val_accuracy: 0.5338\n",
      "Epoch 7/20\n",
      "50000/50000 [==============================] - 6s 113us/sample - loss: 1.2797 - accuracy: 0.5451 - val_loss: 1.2565 - val_accuracy: 0.5448\n",
      "Epoch 8/20\n",
      "50000/50000 [==============================] - 6s 113us/sample - loss: 1.2494 - accuracy: 0.5564 - val_loss: 1.2152 - val_accuracy: 0.5528\n",
      "Epoch 9/20\n",
      "50000/50000 [==============================] - 6s 112us/sample - loss: 1.2265 - accuracy: 0.5650 - val_loss: 1.2004 - val_accuracy: 0.5573\n",
      "Epoch 10/20\n",
      "50000/50000 [==============================] - 6s 113us/sample - loss: 1.2031 - accuracy: 0.5745 - val_loss: 1.1936 - val_accuracy: 0.5693\n",
      "Epoch 11/20\n",
      "50000/50000 [==============================] - 6s 114us/sample - loss: 1.1815 - accuracy: 0.5831 - val_loss: 1.1725 - val_accuracy: 0.5783\n",
      "Epoch 12/20\n",
      "50000/50000 [==============================] - 6s 114us/sample - loss: 1.1622 - accuracy: 0.5892 - val_loss: 1.1389 - val_accuracy: 0.5778\n",
      "Epoch 13/20\n",
      "50000/50000 [==============================] - 6s 113us/sample - loss: 1.1424 - accuracy: 0.5989 - val_loss: 1.1266 - val_accuracy: 0.5883\n",
      "Epoch 14/20\n",
      "50000/50000 [==============================] - 6s 113us/sample - loss: 1.1273 - accuracy: 0.6006 - val_loss: 1.0980 - val_accuracy: 0.6028\n",
      "Epoch 15/20\n",
      "50000/50000 [==============================] - 6s 113us/sample - loss: 1.1112 - accuracy: 0.6089 - val_loss: 1.0970 - val_accuracy: 0.6058\n",
      "Epoch 16/20\n",
      "50000/50000 [==============================] - 6s 115us/sample - loss: 1.0950 - accuracy: 0.6150 - val_loss: 1.0826 - val_accuracy: 0.6198\n",
      "Epoch 17/20\n",
      "50000/50000 [==============================] - 6s 113us/sample - loss: 1.0810 - accuracy: 0.6217 - val_loss: 1.0538 - val_accuracy: 0.6228\n",
      "Epoch 18/20\n",
      "50000/50000 [==============================] - 6s 113us/sample - loss: 1.0656 - accuracy: 0.6233 - val_loss: 1.0398 - val_accuracy: 0.6328\n",
      "Epoch 19/20\n",
      "50000/50000 [==============================] - 6s 114us/sample - loss: 1.0521 - accuracy: 0.6314 - val_loss: 1.0389 - val_accuracy: 0.6258\n",
      "Epoch 20/20\n",
      "50000/50000 [==============================] - 6s 114us/sample - loss: 1.0405 - accuracy: 0.6352 - val_loss: 1.0252 - val_accuracy: 0.6248\n"
     ]
    }
   ],
   "source": [
    "ep=20\n",
    "lra=[5e-3,1e-3,5e-4,1e-4]\n",
    "optimizer = Adam(lr= lra[3])\n",
    "\n",
    "\n",
    "weights_dict = {}\n",
    "\n",
    "weight_callback = tf.keras.callbacks.LambdaCallback \\\n",
    "( on_epoch_end=lambda epoch, logs: weights_dict.update({epoch:model.get_weights()}))\n",
    "\n",
    "\n",
    "model.compile(optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    " \n",
    "\n",
    "\n",
    "hb1=model.fit(x_train,y_train, epochs=20, validation_data=(x_test, y_test), callbacks = [weight_callback  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def impr(im):\n",
    "    ar=[]\n",
    "    img = np.asarray(im) \n",
    "    ar.append(img) \n",
    "    ay = np.asarray(ar)\n",
    "    return ay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Tsoftmax(ed,nu=1.0):\n",
    "    beta=-(nu+1)/2\n",
    "    of=K.ones_like(ed)\n",
    "    x=add([ed,of])\n",
    "    x=Lambda(lambda x: x**beta)(x)\n",
    "    s=tf.reduce_sum(tf.abs(x))\n",
    "    y=Lambda(lambda x: x[0]/x[1])([x,s])\n",
    "    return y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_16\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_33 (InputLayer)           [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 32, 32, 64)   1792        input_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_64 (MaxPooling2D) (None, 16, 16, 64)   0           conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 16, 16, 32)   18464       max_pooling2d_64[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_65 (MaxPooling2D) (None, 8, 8, 32)     0           conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 8, 8, 16)     4624        max_pooling2d_65[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_32 (Flatten)            (None, 1024)         0           conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)            (None, 1024)         0           flatten_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_31 (Dense)                (None, 10)           10250       dropout_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ones_like_26/Shape  [(2,)]               0           dense_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ones_like_26 (Tenso [(None, 10)]         0           tf_op_layer_ones_like_26/Shape[0]\n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 10)           0           dense_31[0][0]                   \n",
      "                                                                 tf_op_layer_ones_like_26[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_25 (Lambda)              (None, 10)           0           add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Abs_3 (TensorFlowOp [(None, 10)]         0           lambda_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sum_3 (TensorFlowOp [()]                 0           tf_op_layer_Abs_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_26 (Lambda)              (None, 10)           0           lambda_25[0][0]                  \n",
      "                                                                 tf_op_layer_Sum_3[0][0]          \n",
      "==================================================================================================\n",
      "Total params: 35,130\n",
      "Trainable params: 35,130\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=input_shape)\n",
    "y = Conv2D(filters=filters,kernel_size=kernel_size,activation='relu',padding='same')(inputs)\n",
    "y = MaxPooling2D()(y)\n",
    "y = Conv2D(filters=filters//2,kernel_size=kernel_size,activation='relu',padding='same')(y)\n",
    "y = MaxPooling2D()(y)\n",
    "y = Conv2D(filters=filters//4,kernel_size=kernel_size,activation='relu',padding='same')(y)\n",
    " \n",
    "y = Flatten()(y)\n",
    " \n",
    "y = Dropout(dropout)(y)\n",
    "outputs = Dense(num_labels, activation='relu')(y)\n",
    "o=Tsoftmax(outputs)\n",
    "\n",
    " \n",
    "model = Model(inputs=inputs, outputs=o)\n",
    " \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 1999 samples\n",
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 7s 139us/sample - loss: 2.0417 - accuracy: 0.2474 - val_loss: 1.8092 - val_accuracy: 0.3537\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 6s 126us/sample - loss: 1.7800 - accuracy: 0.3549 - val_loss: 1.7038 - val_accuracy: 0.4012\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 6s 125us/sample - loss: 1.7046 - accuracy: 0.3820 - val_loss: 1.6671 - val_accuracy: 0.4097\n",
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 6s 126us/sample - loss: 1.6511 - accuracy: 0.3984 - val_loss: 1.6107 - val_accuracy: 0.4172\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 6s 126us/sample - loss: 1.6027 - accuracy: 0.4170 - val_loss: 1.5792 - val_accuracy: 0.4257\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 6s 125us/sample - loss: 1.5693 - accuracy: 0.4277 - val_loss: 1.5650 - val_accuracy: 0.4407\n",
      "Epoch 7/20\n",
      "50000/50000 [==============================] - 6s 126us/sample - loss: 1.5394 - accuracy: 0.4399 - val_loss: 1.5224 - val_accuracy: 0.4537\n",
      "Epoch 8/20\n",
      "50000/50000 [==============================] - 6s 125us/sample - loss: 1.5134 - accuracy: 0.4509 - val_loss: 1.4927 - val_accuracy: 0.4582\n",
      "Epoch 9/20\n",
      "50000/50000 [==============================] - 6s 127us/sample - loss: 1.4895 - accuracy: 0.4594 - val_loss: 1.4706 - val_accuracy: 0.4637\n",
      "Epoch 10/20\n",
      "50000/50000 [==============================] - 6s 127us/sample - loss: 1.4667 - accuracy: 0.4691 - val_loss: 1.4619 - val_accuracy: 0.4677\n",
      "Epoch 11/20\n",
      "50000/50000 [==============================] - 6s 126us/sample - loss: 1.4482 - accuracy: 0.4818 - val_loss: 1.4412 - val_accuracy: 0.4867\n",
      "Epoch 12/20\n",
      "50000/50000 [==============================] - 6s 127us/sample - loss: 1.4333 - accuracy: 0.4842 - val_loss: 1.4318 - val_accuracy: 0.4962\n",
      "Epoch 13/20\n",
      "50000/50000 [==============================] - 6s 126us/sample - loss: 1.4168 - accuracy: 0.4922 - val_loss: 1.4056 - val_accuracy: 0.5053\n",
      "Epoch 14/20\n",
      "50000/50000 [==============================] - 6s 126us/sample - loss: 1.4063 - accuracy: 0.5000 - val_loss: 1.4134 - val_accuracy: 0.4932\n",
      "Epoch 15/20\n",
      "50000/50000 [==============================] - 6s 127us/sample - loss: 1.3938 - accuracy: 0.5038 - val_loss: 1.3880 - val_accuracy: 0.5048\n",
      "Epoch 16/20\n",
      "50000/50000 [==============================] - 6s 127us/sample - loss: 1.3790 - accuracy: 0.5108 - val_loss: 1.3817 - val_accuracy: 0.5088\n",
      "Epoch 17/20\n",
      "50000/50000 [==============================] - 6s 125us/sample - loss: 1.3704 - accuracy: 0.5164 - val_loss: 1.3723 - val_accuracy: 0.5133\n",
      "Epoch 18/20\n",
      "50000/50000 [==============================] - 6s 129us/sample - loss: 1.3578 - accuracy: 0.5215 - val_loss: 1.3578 - val_accuracy: 0.5273\n",
      "Epoch 19/20\n",
      "50000/50000 [==============================] - 6s 125us/sample - loss: 1.3510 - accuracy: 0.5270 - val_loss: 1.3689 - val_accuracy: 0.5158\n",
      "Epoch 20/20\n",
      "50000/50000 [==============================] - 6s 123us/sample - loss: 1.3433 - accuracy: 0.5249 - val_loss: 1.3539 - val_accuracy: 0.5458\n"
     ]
    }
   ],
   "source": [
    "ep=20\n",
    "lra=[5e-3,1e-3,5e-4,1e-4]\n",
    "optimizer = Adam(lr= lra[3])\n",
    "\n",
    "\n",
    "weights_dict = {}\n",
    "\n",
    "weight_callback = tf.keras.callbacks.LambdaCallback \\\n",
    "( on_epoch_end=lambda epoch, logs: weights_dict.update({epoch:model.get_weights()}))\n",
    "\n",
    "\n",
    "model.compile(optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    " \n",
    "\n",
    "\n",
    "hb1=model.fit(x_train,y_train, epochs=20, validation_data=(x_test, y_test), callbacks = [weight_callback  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Bdeep] *",
   "language": "python",
   "name": "conda-env-Bdeep-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
